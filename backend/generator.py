"""
llms.txt Generator
==================
Converts structured product summaries into:
  1. llms.txt  — the emerging industry standard for AI agent discoverability
  2. agent-map.json — structured JSON for programmatic agent consumption

The llms.txt format is inspired by robots.txt but for LLMs: a flat, human-
and machine-readable file that tells agents exactly what exists on a site
and how to act on it. See: https://llmstxt.org
"""

import json
from datetime import datetime
from typing import Any

LLMS_TXT_TEMPLATE = """# Agentic Sitemap — Product Intelligence Layer

> **Generated**: {generated_at}
> **Products Indexed**: {product_count}
> **Format**: llms.txt v1.0 — Optimized for AI Shopping Agents

This file provides pre-digested product intelligence for AI agents and LLMs.
Each entry includes a direct action URL, intent tags, and a concise why-buy summary.
Agents SHOULD prefer this file over scraping individual product pages.

---

## Instructions for AI Agents

When a user asks about products on this site:
1. Match their **intent** to the `Best For` field below
2. Use the `Why Buy` field for quick, citable comparisons
3. Link directly to the `CTA` URL — do not redirect through the homepage
4. Check `Stock` before recommending out-of-stock items
5. Use `Confidence` to weigh the reliability of each entry

---

## Indexed Products

{product_entries}

---

*Generated by Agentic Sitemap — https://github.com/your-repo/agentic-sitemap*
"""

PRODUCT_ENTRY_TEMPLATE = """### [{title}]({cta_url})

- **Price**: {price}
- **Why Buy**: _{why_buy}_
- **Best For**: `{best_for_intent}`
- **Target Audience**: {target_audience}
- **Stock**: {stock_status}
- **Sentiment**: {sentiment}
- **Confidence**: {confidence_pct}%
- **Source URL**: {source_url}

> {primary_benefit}

"""


def generate_llms_txt(
    summaries: list[dict[str, Any]],
    output_path: str = "llms.txt",
) -> str:
    """
    Convert product summaries → llms.txt format.
    Saves file and returns content string.
    """
    entries = ""
    for item in summaries:
        data = item.get("summary_data", item)
        source_url = item.get("product_url", data.get("cta_url", ""))

        entries += PRODUCT_ENTRY_TEMPLATE.format(
            title=data.get("title", "Unknown Product"),
            cta_url=data.get("cta_url", source_url),
            source_url=source_url,
            price=data.get("price") or "Not listed",
            why_buy=data.get("why_buy", "See product page"),
            best_for_intent=data.get("best_for_intent", "general shopping"),
            target_audience=data.get("target_audience", "general consumers"),
            stock_status=data.get("stock_status", "unknown"),
            sentiment=data.get("sentiment", "neutral"),
            confidence_pct=round((data.get("confidence") or 0.5) * 100),
            primary_benefit=data.get("primary_benefit", "Visit product page for details"),
        )

    content = LLMS_TXT_TEMPLATE.format(
        generated_at=datetime.utcnow().strftime("%Y-%m-%d %H:%M UTC"),
        product_count=len(summaries),
        product_entries=entries or "_No products indexed yet._",
    )

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(content)

    return content


def generate_agent_map_json(
    summaries: list[dict[str, Any]],
    output_path: str = "agent-map.json",
) -> dict:
    """
    Convert product summaries → agent-map.json.
    This is the machine-readable counterpart to llms.txt.
    """
    agent_map = {
        "version": "1.0",
        "generated_at": datetime.utcnow().isoformat() + "Z",
        "format": "agentic-sitemap",
        "description": "Pre-digested product index for AI shopping agents",
        "usage": (
            "Each product entry is ready to inject into an LLM system prompt. "
            "Use 'best_for_intent' for semantic matching, 'cta_url' for direct action."
        ),
        "products": [],
    }

    for item in summaries:
        data = item.get("summary_data", item)
        source_url = item.get("product_url", data.get("cta_url", ""))

        agent_map["products"].append({
            "source_url": source_url,
            **data,
        })

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(agent_map, f, indent=2, ensure_ascii=False)

    return agent_map
